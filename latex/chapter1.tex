\pagenumbering{arabic} % switch to Arabic numerals for page numbers
\setcounter{page}{1}  % set page number to 1
\cite{Sakai2007}
\chapter{Introduction}
 Conventional search engines use some technologies to index documents and apply some algorithms to retrieve from those index files. But in some cases, resources of original documents are hard to achieve and easy to be ignored. For example, in the web search application, the documents are obtained from the crawlers, or named spiders. Most of these spiders can crawler information that exists on the internet, however, some webpages are not statically presented. These pages are generated by fetching data from their internal database. And in another scenario, in the desktop search \cite{Thomas2010}, the search engine is aimed to provide an integrated  interface to access to all of an individual's information. The information is always varies in data structure and are distributed in different applications. In both of the situations, the documents can be extremely hard to achieve and indexing the documents would be a great challenge. To tackle problem in such a case, the technique of meta-search has been proposed. \textit{Meta-search} is a technique that combine the search results from different search engines to a single point for users to access. In a typical meta-search engine architecture, the core component is called \textit{broker}, which get queries from users and allocate the queries to its component search engines and then merge the results retrieved by those search engines. Following this procedures, four challenges of meta-search remains to be \textit{Collection representation}, \textit{Collection selection}, \textit{Result Merging}. And also, \textit{Performance evaluation} turns out to be a great challenge in this area.
 
 \textbf{\emph{Collection representation}},
 Collection representation is a previous process of collection selection. To select which collection is more likely to have documents that is relevant to a particular information needs, the broker need to have some information on the different collections. Those information could be size, content or major topics of the document collections.
 
 \textbf{\emph{Collection selection}},
 In most cases, it is obvious that not all of the collection will contain relevant documents. Due to the cost of bandwidth as well as request time and accuracy of the final result, it is necessary to get rid of some collections that is less possible to have relevant documents. Many efforts have been make to choose among the various collections and many selection algorithms have been proposed.
 
 \textbf{\emph{Result merging}},
 When all the results are retrieved and gathered, it is another challenge to rearrange them in a reasonable order. The page rank algorithms used in different search engines are different in most cases, so the document scores are not comparable to each other. And in other situations, even the document scores are not accessible. The meta-search merging algorithms are trying to output an accurate list of results ranking in order of document relevance.
 
 \textbf{\emph{Performance evaluation}},
 Evaluation of the performance of information retrieval system is always a tough task. Due to the fact that the relevance of documents are based on the relevance of documents to information needs, instead of the query terms, the performance remains to be hard to measure.
 
 In many cases, the number of collection is pretty limited so the collection selection problem becomes a less significant problem. In this paper, the main focus is put on the merging algorithms. As discussed above, result merging algorithms are utilised to get an integrated list of results retrieved by the component search engines. In the first section, we will introduce different merging algorithms that has been proposed in previous works, and then we will compare the advantages as well as disadvantages of those algorithms. Finally, we will examine the performance of different algorithms using our evaluation framework and discuss the performance of those algorithms in a realistic environment.
 